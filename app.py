{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDSXvjihq+UBS39OLMHuT9",
      "include_colab_link": True
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewinggumtnp-cmd/TapMelon-to-Ripe/blob/main/app.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UvJcfBWeA7Sn",
        "outputId": "182de49d-d0a6-4b8d-9e26-241dce82a9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô 'watermelon_dataset' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pillow).\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ ripe: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ mid: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ unripe: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "Found 150 files belonging to 3 classes.\n",
            "Using 120 files for training.\n",
            "Found 150 files belonging to 3 classes.\n",
            "Using 30 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.2835 - loss: 9.0427 - val_accuracy: 0.3667 - val_loss: 1.1394\n",
            "Epoch 2/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.2401 - loss: 1.1460 - val_accuracy: 0.2000 - val_loss: 1.1028\n",
            "Epoch 3/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3760 - loss: 1.0975 - val_accuracy: 0.2000 - val_loss: 1.1083\n",
            "Epoch 4/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.3467 - loss: 1.0975 - val_accuracy: 0.2000 - val_loss: 1.1088\n",
            "Epoch 5/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3800 - loss: 1.0964 - val_accuracy: 0.2000 - val_loss: 1.1124\n",
            "Epoch 6/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3396 - loss: 1.1003 - val_accuracy: 0.2000 - val_loss: 1.1134\n",
            "Epoch 7/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4168 - loss: 1.0915 - val_accuracy: 0.2000 - val_loss: 1.1198\n",
            "Epoch 8/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3485 - loss: 1.0991 - val_accuracy: 0.2000 - val_loss: 1.1139\n",
            "Epoch 9/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4001 - loss: 1.0947 - val_accuracy: 0.2000 - val_loss: 1.1196\n",
            "Epoch 10/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3474 - loss: 1.0994 - val_accuracy: 0.2000 - val_loss: 1.1197\n",
            "Epoch 11/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4038 - loss: 1.0944 - val_accuracy: 0.2000 - val_loss: 1.1215\n",
            "Epoch 12/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3156 - loss: 1.1037 - val_accuracy: 0.2000 - val_loss: 1.1143\n",
            "Epoch 13/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3321 - loss: 1.1019 - val_accuracy: 0.2000 - val_loss: 1.1166\n",
            "Epoch 14/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3984 - loss: 1.0936 - val_accuracy: 0.2000 - val_loss: 1.1256\n",
            "Epoch 15/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4179 - loss: 1.0903 - val_accuracy: 0.2000 - val_loss: 1.1193\n",
            "Epoch 16/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3400 - loss: 1.1004 - val_accuracy: 0.2000 - val_loss: 1.1157\n",
            "Epoch 17/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4040 - loss: 1.0983 - val_accuracy: 0.2000 - val_loss: 1.1187\n",
            "Epoch 18/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3745 - loss: 1.0958 - val_accuracy: 0.2000 - val_loss: 1.1169\n",
            "Epoch 19/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3840 - loss: 1.0959 - val_accuracy: 0.2000 - val_loss: 1.1196\n",
            "Epoch 20/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3567 - loss: 1.0990 - val_accuracy: 0.2000 - val_loss: 1.1174\n",
            "Epoch 21/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3936 - loss: 1.0942 - val_accuracy: 0.2000 - val_loss: 1.1205\n",
            "Epoch 22/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.2943 - loss: 1.1079 - val_accuracy: 0.2000 - val_loss: 1.1152\n",
            "Epoch 23/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.4030 - loss: 1.0934 - val_accuracy: 0.2000 - val_loss: 1.1210\n",
            "Epoch 24/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.2801 - loss: 1.1102 - val_accuracy: 0.2000 - val_loss: 1.1134\n",
            "Epoch 25/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3782 - loss: 1.0987 - val_accuracy: 0.2000 - val_loss: 1.1194\n",
            "Epoch 26/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3120 - loss: 1.1036 - val_accuracy: 0.2000 - val_loss: 1.1165\n",
            "Epoch 27/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3999 - loss: 1.0940 - val_accuracy: 0.2000 - val_loss: 1.1209\n",
            "Epoch 28/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3620 - loss: 1.1009 - val_accuracy: 0.2000 - val_loss: 1.1175\n",
            "Epoch 29/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4483 - loss: 1.0901 - val_accuracy: 0.2000 - val_loss: 1.1200\n",
            "Epoch 30/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3724 - loss: 1.0949 - val_accuracy: 0.2000 - val_loss: 1.1164\n",
            "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-378575319.py:144: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(file_path, duration=1.0) # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏ó‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'watermelon_unripe_3_1.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'watermelon_unripe_3_1.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-378575319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m#‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• (Prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# ‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mnew_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watermelon_unripe_3_1.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;31m# 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-378575319.py\u001b[0m in \u001b[0;36mprepare_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏ó‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;31m# 2. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mel Spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-122>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'watermelon_unripe_3_1.wav'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import os module for directory operations\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ---\n",
        "IMG_HEIGHT = 224  # ‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å 1892 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 224\n",
        "IMG_WIDTH = 224  # ‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å 872 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 224\n",
        "BATCH_SIZE = 8  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢ ‡πÉ‡∏ä‡πâ Batch ‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "DATA_DIR = 'watermelon_dataset'  # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢: ripe, mid, unripe)\n",
        "\n",
        "# --- ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
        "# ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà Keras ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô .jpg ‡∏´‡∏£‡∏∑‡∏≠ .png\n",
        "# ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ ‡πÅ‡∏ï‡πà Keras image_dataset_from_directory ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Pillow ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏≠‡∏∑‡πà‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "# ‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå dummy .txt ‡πÅ‡∏ó‡∏ô (‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î error ‡∏≠‡∏µ‡∏Å‡∏´‡∏≤‡∏Å Keras ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô)\n",
        "# ‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "\n",
        "# Ensure the base data directory exists\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Ensure subdirectories for each class exist before attempting to save files\n",
        "for label_folder in ['ripe', 'mid', 'unripe']:\n",
        "    os.makedirs(os.path.join(DATA_DIR, label_folder), exist_ok=True)\n",
        "\n",
        "# ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏î NotFoundError ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î InvalidArgumentError ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡∏•‡πà‡∏≤\n",
        "# ‡∏ú‡∏°‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å‡πÜ ‡∏î‡πâ‡∏ß‡∏¢ Pillow ‡∏´‡∏≤‡∏Å Pillow ‡∏°‡∏µ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°\n",
        "try:\n",
        "    from PIL import Image\n",
        "    dummy_image = Image.new('RGB', (IMG_WIDTH, IMG_HEIGHT), color = 'red')\n",
        "    for i in range(50): # ‡∏™‡∏£‡πâ‡∏≤‡∏á 50 ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'ripe', f'dummy_ripe_{i}.jpg'))\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'mid', f'dummy_mid_{i}.jpg'))\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'unripe', f'dummy_unripe_{i}.jpg'))\n",
        "    print(f\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô '{DATA_DIR}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pillow).\")\n",
        "except ImportError:\n",
        "    print(\"Pillow ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á. ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÑ‡∏î‡πâ. ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á.\")\n",
        "    # Fallback to create dummy .txt files. Directories are already created above.\n",
        "    open(os.path.join(DATA_DIR, 'ripe', 'dummy.txt'), 'a').close()\n",
        "    open(os.path.join(DATA_DIR, 'mid', 'dummy.txt'), 'a').close()\n",
        "    open(os.path.join(DATA_DIR, 'unripe', 'dummy.txt'), 'a').close()\n",
        "    print(f\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .txt ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô '{DATA_DIR}' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á NotFoundError (‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î error ‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏ó‡∏ô).\")\n",
        "\n",
        "import os\n",
        "\n",
        "# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "for label in ['ripe', 'mid', 'unripe']:\n",
        "    path = os.path.join(DATA_DIR, label)\n",
        "    if os.path.exists(path):\n",
        "        count = len(os.listdir(path))\n",
        "        print(f\"‡∏Ñ‡∏•‡∏≤‡∏™ {label}: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û {count} ‡∏£‡∏π‡∏õ\")\n",
        "    else:\n",
        "        print(f\"‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {label} ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠! ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö\")\n",
        "\n",
        "# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ---\n",
        "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå ‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏™‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n",
        "try:\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        DATA_DIR,\n",
        "        validation_split=0.2,  # ‡πÅ‡∏ö‡πà‡∏á 20% ‡πÑ‡∏ß‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 72 ‡∏£‡∏π‡∏õ)\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        DATA_DIR,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}\")\n",
        "    print(\"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'watermelon_dataset' ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢ ripe, mid, unripe) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á\")\n",
        "    # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n",
        "    raise\n",
        "\n",
        "#‡∏Ç‡πâ‡∏≤‡∏°‡∏¢‡πâ‡∏≤‡∏¢ 3.‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡∏£‡∏Å‡πÉ‡∏ô 4\n",
        "\n",
        "# --- 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN (‡πÅ‡∏ó‡∏£‡∏Å Data Augmentation ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà) ---\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # --- ‡πÉ‡∏™‡πà Data Augmentation ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ---\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "\n",
        "    # --- ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Layer ‡∏õ‡∏Å‡∏ï‡∏¥ ---\n",
        "    layers.Rescaling(1./255), # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏µ\n",
        "\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ (ripe, mid, unripe)\n",
        "    layers.Dense(3)\n",
        "])\n",
        "\n",
        "# --- 5. ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ---\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Optimizer, Loss function ‡πÅ‡∏•‡∏∞ Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 6. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô (Training) ---\n",
        "epochs = 30  # ‡∏•‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô 30 ‡∏£‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° (‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô Warning)\n",
        "# model.save('watermelon_model.h5')\n",
        "\n",
        "# ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Warning ‡∏à‡∏∞‡∏´‡∏≤‡∏¢‡πÑ‡∏õ)\n",
        "model.save('watermelon_model.keras')\n",
        "print(\"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .keras ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "model = load_model('watermelon_model.keras')\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "# prepare_audio function needs to be defined BEFORE it is used.\n",
        "#‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (Preprocessing Pipeline)\n",
        "def prepare_audio(file_path):\n",
        "    # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
        "    y, sr = librosa.load(file_path, duration=1.0) # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏ó‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\n",
        "    # 2. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mel Spectrogram\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "    # 3. ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û (Resize) ‡πÅ‡∏•‡∏∞ Normalization\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á (IMG_HEIGHT, IMG_WIDTH)\n",
        "    img = tf.image.resize(S_dB[..., np.newaxis], [IMG_HEIGHT, IMG_WIDTH])\n",
        "    # ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÅ‡∏ä‡∏ô‡πÄ‡∏ô‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏õ‡πá‡∏ô 3 ‡πÅ‡∏ä‡∏ô‡πÄ‡∏ô‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û RGB\n",
        "    img = tf.concat([img, img, img], axis=-1)\n",
        "    img = img / 255.0  # ‡∏ó‡∏≥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\n",
        "    # 4. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥ Batch (‡πÄ‡∏õ‡πá‡∏ô [1, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "#‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• (Prediction)\n",
        "# ‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "new_audio = prepare_audio('watermelon_unripe_3_1.wav')\n",
        "\n",
        "# 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "predictions = model.predict(new_audio)\n",
        "\n",
        "# 2. ‡πÉ‡∏ä‡πâ Softmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probability) 0-100%\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ predictions ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡πÅ‡∏£‡∏Å [0]\n",
        "prob = softmax(predictions[0])\n",
        "\n",
        "classes = ['Mid', 'Ripe', 'Unripe']\n",
        "\n",
        "# 3. ‡∏î‡∏∂‡∏á Index ‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
        "result_index = np.argmax(prob)\n",
        "\n",
        "# 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "print(f\"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {classes[result_index]}\")\n",
        "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {prob[result_index]*100:.2f}%\")\n",
        "print(f\"‡∏Ñ‡πà‡∏≤ Probability ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {prob}\") # ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ 1.0 ‡∏û‡∏≠‡∏î‡∏µ\n",
        "\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ)\n",
        "model = tf.keras.models.load_model('watermelon_model.keras')\n",
        "\n",
        "\n",
        "#‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• (Prediction)\n",
        "# ‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "new_audio = prepare_audio('watermelon_unripe_3_1.wav')\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢\n",
        "predictions = model.predict(new_audio)\n",
        "classes = ['Mid', 'Ripe', 'Unripe']\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤\n",
        "result_index = np.argmax(predictions)\n",
        "print(f\"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {classes[result_index]} (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {predictions[0][result_index]*100:.2f}%) errors: {predictions[0]}\")\n",
        "\n",
        "import streamlit as st\n",
        "from st_audiorec import st_audiorec\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ TensorFlow\n",
        "\n",
        "# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Keras ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ö‡∏ô GitHub\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 'watermelon_model.keras')\n",
        "try:\n",
        "    model = tf.keras.models.load_model('watermelon_model.keras')\n",
        "    st.success(\"‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}\")\n",
        "    st.stop() # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n",
        "\n",
        "st.title(\"TapMelon-to-Ripe\")\n",
        "st.write(\"‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏Ñ‡∏≤‡∏∞‡πÅ‡∏ï‡∏á‡πÇ‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Å\")\n",
        "\n",
        "wav_audio_data = st_audiorec()\n",
        "\n",
        "if wav_audio_data is not None:\n",
        "    st.audio(wav_audio_data, format='audio/wav')\n",
        "    st.info(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á...\")\n",
        "\n",
        "    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .wav ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ librosa ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
        "    with open(\"temp_audio.wav\", \"wb\") as f:\n",
        "        f.write(wav_audio_data)\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ librosa\n",
        "    y, sr = librosa.load(\"temp_audio.wav\", sr=22050) # ‡∏õ‡∏£‡∏±‡∏ö sr ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤\n",
        "\n",
        "    # ‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ (‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤)\n",
        "    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏™‡∏Å‡∏±‡∏î MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    features = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "    # Keras ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ input ‡πÄ‡∏õ‡πá‡∏ô batch (‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡πÄ‡∏•‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥\n",
        "    input_features = np.expand_dims(features, axis=0)\n",
        "\n",
        "    # 3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "    prediction = model.predict(input_features)\n",
        "\n",
        "    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö logic ‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏° output ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏∏‡∏ì\n",
        "    if prediction[0][0] > 0.5:\n",
        "        result = \"‡∏™‡∏∏‡∏Å‡πÅ‡∏•‡πâ‡∏ß! üéâ\"\n",
        "    else:\n",
        "        result = \"‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏∏‡∏Å  unripe üòï\"\n",
        "\n",
        "    st.metric(\"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Å\", result)\n",
        "\n"
      ]
    }
  ]
}
