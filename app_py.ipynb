{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDSXvjihq+UBS39OLMHuT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewinggumtnp-cmd/TapMelon-to-Ripe/blob/main/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvJcfBWeA7Sn",
        "outputId": "182de49d-d0a6-4b8d-9e26-241dce82a9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô 'watermelon_dataset' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pillow).\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ ripe: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ mid: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™ unripe: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 50 ‡∏£‡∏π‡∏õ\n",
            "Found 150 files belonging to 3 classes.\n",
            "Using 120 files for training.\n",
            "Found 150 files belonging to 3 classes.\n",
            "Using 30 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.2835 - loss: 9.0427 - val_accuracy: 0.3667 - val_loss: 1.1394\n",
            "Epoch 2/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.2401 - loss: 1.1460 - val_accuracy: 0.2000 - val_loss: 1.1028\n",
            "Epoch 3/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3760 - loss: 1.0975 - val_accuracy: 0.2000 - val_loss: 1.1083\n",
            "Epoch 4/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.3467 - loss: 1.0975 - val_accuracy: 0.2000 - val_loss: 1.1088\n",
            "Epoch 5/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3800 - loss: 1.0964 - val_accuracy: 0.2000 - val_loss: 1.1124\n",
            "Epoch 6/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3396 - loss: 1.1003 - val_accuracy: 0.2000 - val_loss: 1.1134\n",
            "Epoch 7/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4168 - loss: 1.0915 - val_accuracy: 0.2000 - val_loss: 1.1198\n",
            "Epoch 8/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3485 - loss: 1.0991 - val_accuracy: 0.2000 - val_loss: 1.1139\n",
            "Epoch 9/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4001 - loss: 1.0947 - val_accuracy: 0.2000 - val_loss: 1.1196\n",
            "Epoch 10/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3474 - loss: 1.0994 - val_accuracy: 0.2000 - val_loss: 1.1197\n",
            "Epoch 11/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4038 - loss: 1.0944 - val_accuracy: 0.2000 - val_loss: 1.1215\n",
            "Epoch 12/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3156 - loss: 1.1037 - val_accuracy: 0.2000 - val_loss: 1.1143\n",
            "Epoch 13/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3321 - loss: 1.1019 - val_accuracy: 0.2000 - val_loss: 1.1166\n",
            "Epoch 14/30\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3984 - loss: 1.0936 - val_accuracy: 0.2000 - val_loss: 1.1256\n",
            "Epoch 15/30\n",
            "\u001b[1m11/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.4487 - loss: 1.0855"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import os module for directory operations\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ---\n",
        "IMG_HEIGHT = 224  # ‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å 1892 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 224\n",
        "IMG_WIDTH = 224  # ‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å 872 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 224\n",
        "BATCH_SIZE = 8  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢ ‡πÉ‡∏ä‡πâ Batch ‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "DATA_DIR = 'watermelon_dataset'  # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢: ripe, mid, unripe)\n",
        "\n",
        "# --- ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
        "# ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà Keras ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô .jpg ‡∏´‡∏£‡∏∑‡∏≠ .png\n",
        "# ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ ‡πÅ‡∏ï‡πà Keras image_dataset_from_directory ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Pillow ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏≠‡∏∑‡πà‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "# ‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå dummy .txt ‡πÅ‡∏ó‡∏ô (‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î error ‡∏≠‡∏µ‡∏Å‡∏´‡∏≤‡∏Å Keras ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô)\n",
        "# ‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á\n",
        "\n",
        "# Ensure the base data directory exists\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Ensure subdirectories for each class exist before attempting to save files\n",
        "for label_folder in ['ripe', 'mid', 'unripe']:\n",
        "    os.makedirs(os.path.join(DATA_DIR, label_folder), exist_ok=True)\n",
        "\n",
        "# ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏î NotFoundError ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î InvalidArgumentError ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡∏•‡πà‡∏≤\n",
        "# ‡∏ú‡∏°‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å‡πÜ ‡∏î‡πâ‡∏ß‡∏¢ Pillow ‡∏´‡∏≤‡∏Å Pillow ‡∏°‡∏µ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°\n",
        "try:\n",
        "    from PIL import Image\n",
        "    dummy_image = Image.new('RGB', (IMG_WIDTH, IMG_HEIGHT), color = 'red')\n",
        "    for i in range(50): # ‡∏™‡∏£‡πâ‡∏≤‡∏á 50 ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'ripe', f'dummy_ripe_{i}.jpg'))\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'mid', f'dummy_mid_{i}.jpg'))\n",
        "        dummy_image.save(os.path.join(DATA_DIR, 'unripe', f'dummy_unripe_{i}.jpg'))\n",
        "    print(f\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô '{DATA_DIR}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Pillow).\")\n",
        "except ImportError:\n",
        "    print(\"Pillow ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á. ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÑ‡∏î‡πâ. ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á.\")\n",
        "    # Fallback to create dummy .txt files. Directories are already created above.\n",
        "    open(os.path.join(DATA_DIR, 'ripe', 'dummy.txt'), 'a').close()\n",
        "    open(os.path.join(DATA_DIR, 'mid', 'dummy.txt'), 'a').close()\n",
        "    open(os.path.join(DATA_DIR, 'unripe', 'dummy.txt'), 'a').close()\n",
        "    print(f\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .txt ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô '{DATA_DIR}' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á NotFoundError (‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î error ‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏ó‡∏ô).\")\n",
        "\n",
        "import os\n",
        "\n",
        "# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "for label in ['ripe', 'mid', 'unripe']:\n",
        "    path = os.path.join(DATA_DIR, label)\n",
        "    if os.path.exists(path):\n",
        "        count = len(os.listdir(path))\n",
        "        print(f\"‡∏Ñ‡∏•‡∏≤‡∏™ {label}: ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û {count} ‡∏£‡∏π‡∏õ\")\n",
        "    else:\n",
        "        print(f\"‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {label} ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠! ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö\")\n",
        "\n",
        "# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ---\n",
        "# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå ‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏™‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n",
        "try:\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        DATA_DIR,\n",
        "        validation_split=0.2,  # ‡πÅ‡∏ö‡πà‡∏á 20% ‡πÑ‡∏ß‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 72 ‡∏£‡∏π‡∏õ)\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        DATA_DIR,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}\")\n",
        "    print(\"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'watermelon_dataset' ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢ ripe, mid, unripe) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á\")\n",
        "    # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n",
        "    raise\n",
        "\n",
        "#‡∏Ç‡πâ‡∏≤‡∏°‡∏¢‡πâ‡∏≤‡∏¢ 3.‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡∏£‡∏Å‡πÉ‡∏ô 4\n",
        "\n",
        "# --- 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN (‡πÅ‡∏ó‡∏£‡∏Å Data Augmentation ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà) ---\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # --- ‡πÉ‡∏™‡πà Data Augmentation ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ---\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "\n",
        "    # --- ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Layer ‡∏õ‡∏Å‡∏ï‡∏¥ ---\n",
        "    layers.Rescaling(1./255), # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏µ\n",
        "\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ (ripe, mid, unripe)\n",
        "    layers.Dense(3)\n",
        "])\n",
        "\n",
        "# --- 5. ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ---\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Optimizer, Loss function ‡πÅ‡∏•‡∏∞ Metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 6. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô (Training) ---\n",
        "epochs = 30  # ‡∏•‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô 30 ‡∏£‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° (‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô Warning)\n",
        "# model.save('watermelon_model.h5')\n",
        "\n",
        "# ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Warning ‡∏à‡∏∞‡∏´‡∏≤‡∏¢‡πÑ‡∏õ)\n",
        "model.save('watermelon_model.keras')\n",
        "print(\"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .keras ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "model = load_model('watermelon_model.keras')\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "# prepare_audio function needs to be defined BEFORE it is used.\n",
        "#‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (Preprocessing Pipeline)\n",
        "def prepare_audio(file_path):\n",
        "    # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
        "    y, sr = librosa.load(file_path, duration=1.0) # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏ó‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\n",
        "    # 2. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mel Spectrogram\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "    # 3. ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û (Resize) ‡πÅ‡∏•‡∏∞ Normalization\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á (IMG_HEIGHT, IMG_WIDTH)\n",
        "    img = tf.image.resize(S_dB[..., np.newaxis], [IMG_HEIGHT, IMG_WIDTH])\n",
        "    # ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÅ‡∏ä‡∏ô‡πÄ‡∏ô‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏õ‡πá‡∏ô 3 ‡πÅ‡∏ä‡∏ô‡πÄ‡∏ô‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û RGB\n",
        "    img = tf.concat([img, img, img], axis=-1)\n",
        "    img = img / 255.0  # ‡∏ó‡∏≥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô\n",
        "    # 4. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥ Batch (‡πÄ‡∏õ‡πá‡∏ô [1, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "#‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• (Prediction)\n",
        "# ‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "new_audio = prepare_audio('watermelon_unripe_3_1.wav')\n",
        "\n",
        "# 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "predictions = model.predict(new_audio)\n",
        "\n",
        "# 2. ‡πÉ‡∏ä‡πâ Softmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probability) 0-100%\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ predictions ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡πÅ‡∏£‡∏Å [0]\n",
        "prob = softmax(predictions[0])\n",
        "\n",
        "classes = ['Mid', 'Ripe', 'Unripe']\n",
        "\n",
        "# 3. ‡∏î‡∏∂‡∏á Index ‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
        "result_index = np.argmax(prob)\n",
        "\n",
        "# 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "print(f\"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {classes[result_index]}\")\n",
        "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {prob[result_index]*100:.2f}%\")\n",
        "print(f\"‡∏Ñ‡πà‡∏≤ Probability ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {prob}\") # ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ 1.0 ‡∏û‡∏≠‡∏î‡∏µ\n",
        "\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ)\n",
        "model = tf.keras.models.load_model('watermelon_model.keras')\n",
        "\n",
        "\n",
        "#‡∏™‡∏±‡πà‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• (Prediction)\n",
        "# ‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "new_audio = prepare_audio('watermelon_unripe_3_1.wav')\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢\n",
        "predictions = model.predict(new_audio)\n",
        "classes = ['Mid', 'Ripe', 'Unripe']\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤\n",
        "result_index = np.argmax(predictions)\n",
        "print(f\"‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {classes[result_index]} (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {predictions[0][result_index]*100:.2f}%) errors: {predictions[0]}\")\n",
        "\n",
        "import streamlit as st\n",
        "from st_audiorec import st_audiorec\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ TensorFlow\n",
        "\n",
        "# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Keras ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ö‡∏ô GitHub\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 'watermelon_model.keras')\n",
        "try:\n",
        "    model = tf.keras.models.load_model('watermelon_model.keras')\n",
        "    st.success(\"‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}\")\n",
        "    st.stop() # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n",
        "\n",
        "st.title(\"TapMelon-to-Ripe\")\n",
        "st.write(\"‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏Ñ‡∏≤‡∏∞‡πÅ‡∏ï‡∏á‡πÇ‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Å\")\n",
        "\n",
        "wav_audio_data = st_audiorec()\n",
        "\n",
        "if wav_audio_data is not None:\n",
        "    st.audio(wav_audio_data, format='audio/wav')\n",
        "    st.info(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á...\")\n",
        "\n",
        "    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .wav ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ librosa ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
        "    with open(\"temp_audio.wav\", \"wb\") as f:\n",
        "        f.write(wav_audio_data)\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ librosa\n",
        "    y, sr = librosa.load(\"temp_audio.wav\", sr=22050) # ‡∏õ‡∏£‡∏±‡∏ö sr ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤\n",
        "\n",
        "    # ‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ (‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤)\n",
        "    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏™‡∏Å‡∏±‡∏î MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    features = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "    # Keras ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ input ‡πÄ‡∏õ‡πá‡∏ô batch (‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡πÄ‡∏•‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥\n",
        "    input_features = np.expand_dims(features, axis=0)\n",
        "\n",
        "    # 3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "    prediction = model.predict(input_features)\n",
        "\n",
        "    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö logic ‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏° output ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏∏‡∏ì\n",
        "    if prediction[0][0] > 0.5:\n",
        "        result = \"‡∏™‡∏∏‡∏Å‡πÅ‡∏•‡πâ‡∏ß! üéâ\"\n",
        "    else:\n",
        "        result = \"‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏∏‡∏Å  unripe üòï\"\n",
        "\n",
        "    st.metric(\"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Å\", result)\n",
        "\n"
      ]
    }
  ]
}